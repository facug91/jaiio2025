{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c207e8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/facug91/repos/jaiio2025/mlflow/artifacts/1', creation_time=1753988965723, experiment_id='1', last_update_time=1753988965723, lifecycle_stage='active', name='mnist-classifier', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from datetime import datetime\n",
    "from mlflow.tracking import MlflowClient\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"mnist-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3593860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders():\n",
    "\n",
    "    print(\"Creating data loaders\")\n",
    "\n",
    "    BATCH_SIZE = 1024\n",
    "\n",
    "    dataloader_kwargs = {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_workers': 1,\n",
    "        'persistent_workers': True,\n",
    "        'pin_memory': True,\n",
    "        'shuffle': True\n",
    "    }\n",
    "\n",
    "    data_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "    train_dataset_full = datasets.MNIST(root='./data', train=True, download=True, transform=data_transform)\n",
    "\n",
    "    train_size = int(0.85 * len(train_dataset_full))\n",
    "    val_size = len(train_dataset_full) - train_size\n",
    "\n",
    "    seed = 42\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        train_dataset_full, [train_size, val_size], generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=data_transform)\n",
    "\n",
    "    dataloaders = {}\n",
    "    dataloaders[\"train\"] = DataLoader(train_dataset,**dataloader_kwargs)\n",
    "    dataloaders[\"val\"] = DataLoader(val_dataset, **dataloader_kwargs)\n",
    "    dataloaders[\"test\"] = DataLoader(test_dataset, **dataloader_kwargs)\n",
    "\n",
    "    print(\"Data loaders created successfully\")\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6ee126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47351ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, dataloaders, num_epochs):\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "\n",
    "    learning_rate = 1.0\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", \"Adadelta\")\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"scheduler_step_size\", 1)\n",
    "    mlflow.log_param(\"scheduler_gamma\", 0.7)\n",
    "    mlflow.log_param(\"epochs\", num_epochs)\n",
    "    mlflow.log_param(\"batch_size\", dataloaders[\"train\"].batch_size)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print()\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0\n",
    "\n",
    "            # Wrap dataloader with tqdm for progress bar\n",
    "            loop = tqdm(dataloaders[phase], desc=f\"{phase.capitalize()} Phase\", leave=False)\n",
    "\n",
    "            for inputs, labels in loop:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = F.nll_loss(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_correct += torch.sum(preds == labels)\n",
    "\n",
    "                # Update tqdm description dynamically\n",
    "                loop.set_postfix({\n",
    "                    \"Loss\": f\"{loss.item():.4f}\",\n",
    "                    \"Batch Acc\": f\"{(preds == labels).float().mean().item():.4f}\"\n",
    "                })\n",
    "\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_correct.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            mlflow.log_metric(f\"{phase}_loss\", epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(f\"{phase}_acc\", epoch_acc, step=epoch)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            \n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "    mlflow.pytorch.log_model(model, \"model\", registered_model_name=\"MNISTClassifier\")\n",
    "    print(\"\\nTraining complete.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1dad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_confusion_matrix(model, dataloader, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "\n",
    "    os.makedirs(\"artifacts\", exist_ok=True)\n",
    "    cm_path = f\"artifacts/confusion_matrix.png\"\n",
    "    plt.savefig(cm_path)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(cm_path, artifact_path=\"plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e674e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_misclassified_images(model, dataloader, device, max_images=25):\n",
    "    model.eval()\n",
    "    errors = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            mismatches = preds != labels\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                if mismatches[i]:\n",
    "                    errors.append((inputs[i].cpu(), preds[i].item(), labels[i].item()))\n",
    "                if len(errors) >= max_images:\n",
    "                    break\n",
    "            if len(errors) >= max_images:\n",
    "                break\n",
    "\n",
    "    if errors:\n",
    "        fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "        for ax, (img, pred, true) in zip(axes.flat, errors):\n",
    "            ax.imshow(img.squeeze(), cmap=\"gray\")\n",
    "            ax.set_title(f\"P: {pred} / T: {true}\")\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        img_path = \"artifacts/misclassified.png\"\n",
    "        plt.savefig(img_path)\n",
    "        plt.close()\n",
    "\n",
    "        mlflow.log_artifact(img_path, artifact_path=\"plots\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77fdf976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    print(\"\\nStarting testing...\")\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_loss += F.nll_loss(outputs, labels, reduction='sum').item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct.double() / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * test_acc))\n",
    "    \n",
    "    mlflow.log_metric(f\"test_loss\", test_loss)\n",
    "    mlflow.log_metric(f\"test_acc\", test_acc)\n",
    "    \n",
    "    log_confusion_matrix(model, test_loader, device)\n",
    "\n",
    "    log_misclassified_images(model, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38b3ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_workflow():\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"mnist_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "\n",
    "        MANUAL_SEED = 42\n",
    "        torch.manual_seed(MANUAL_SEED)\n",
    "        mlflow.log_param(\"manual_seed\", MANUAL_SEED)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f'Device: {device}\\n')\n",
    "\n",
    "        mlflow.set_tag(\"model_type\", \"LeNet-5\")\n",
    "        mlflow.set_tag(\"data_scientist\", \"Facundo Galan\")\n",
    "        mlflow.set_tag(\"dataset\", \"MNIST\")\n",
    "        mlflow.set_tag(\"framework\", \"PyTorch\")\n",
    "        mlflow.set_tag(\"device\", device)\n",
    "\n",
    "        dataloaders = get_data_loaders()\n",
    "\n",
    "        model = Net().to(device)\n",
    "\n",
    "        train(model, device, dataloaders, num_epochs=5)\n",
    "        \n",
    "        test(model, device, dataloaders[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15af6e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Creating data loaders\n",
      "Data loaders created successfully\n",
      "\n",
      "Starting training...\n",
      "\n",
      "\n",
      "Epoch 1/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8008 Acc: 0.7498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1545 Acc: 0.9532\n",
      "\n",
      "\n",
      "Epoch 2/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1711 Acc: 0.9500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1020 Acc: 0.9691\n",
      "\n",
      "\n",
      "Epoch 3/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1185 Acc: 0.9646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0763 Acc: 0.9779\n",
      "\n",
      "\n",
      "Epoch 4/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0927 Acc: 0.9728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0662 Acc: 0.9798\n",
      "\n",
      "\n",
      "Epoch 5/5\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0832 Acc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 01:40:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0602 Acc: 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/05 01:40:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.7.1+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.7.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/08/05 01:40:14 WARNING mlflow.utils.requirements_utils: Found torch version (2.7.1+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.7.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/05 01:40:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'MNISTClassifier' already exists. Creating a new version of this model...\n",
      "2025/08/05 01:40:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: MNISTClassifier, version 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete.\n",
      "\n",
      "Starting testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'MNISTClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0471, Accuracy: 9838/10000 (98.38%)\n",
      "\n",
      "üèÉ View run mnist_run_20250805_013936 at: http://127.0.0.1:5000/#/experiments/1/runs/f67a83692c5147c797d237f581bdb7e9\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "training_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1003986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144472/3624062240.py:4: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  latest_versions = client.get_latest_versions(model_name, stages=[\"None\"])\n",
      "/tmp/ipykernel_144472/3624062240.py:7: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "model_name = \"MNISTClassifier\"\n",
    "\n",
    "latest_versions = client.get_latest_versions(model_name, stages=[\"None\"])\n",
    "model_version = latest_versions[0].version\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=\"Staging\",  # Tambi√©n puede ser \"Production\", \"Archived\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(model_name, model_version, \"comment\", \"First stable version of MNIST classification model.\")\n",
    "client.set_model_version_tag(model_name, model_version, \"custom_version\", \"v1.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ce2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "image_path = \"/root/workspace/data/three_example.png\"\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "model_uri = \"models:/MNISTClassifier/Staging\"\n",
    "model = mlflow.pytorch.load_model(model_uri).to(device)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    probabilities = torch.exp(output, dim=1)\n",
    "    pred_label = torch.argmax(probabilities, dim=1).item()\n",
    "    confidence = torch.max(probabilities).item()\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.title(f\"Predicci√≥n: {pred_label} (Confianza: {confidence:.2%})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
